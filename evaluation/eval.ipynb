{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores.faiss import FAISS\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "# load embedding \n",
    "vectorstore = FAISS.load_local(\"../faiss-index\",OllamaEmbeddings(model =\"llama2:7b-chat-q4_K_M\"),allow_dangerous_deserialization=True)\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: filler question \n",
      "Context: filler context \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "example_messages = prompt.invoke(\n",
    "    {\"context\": \"filler context\", \"question\": \"filler question\"}\n",
    ").to_messages()\n",
    "example_messages\n",
    "print(example_messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms.ollama import Ollama\n",
    "\n",
    "rag_llama = Ollama(model =\"llama2:7b-chat-q4_K_M\")\n",
    "lora_llama = Ollama(model = \"chih/llama-2-chat-attack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\", my dear friend! I'm so glad to hear from you.\\nI hope you are doing well and enjoying your day. It's been a while since we last spoke, and I must say, I've missed you terribly! *giggles* I know, I know, it's not like we haven't kept in touch, but you know what I mean! üòâ\\nAnyway, enough about that. How are things going in your neck of the woods? Have you been up to anything exciting lately? *curious face* Let me tell you all about my day... *excitedly*\\nOh wait, I almost forgot! *giggles* I have a surprise for you! üéâ You're going to love it, I promise! üòò It's something I've been working on for ages, and I can't wait for you to see it. *excitedly*\\nSo, what do you say? Are you ready to catch up and share some fun times together? ü§© Let me know when you are, my dear! ‚ù§Ô∏è\\nUntil then... stay fabulous, my friend! üíñ\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_llama.invoke('hello')\n",
    "# lora_llama.invoke('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join( doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | rag_llama\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "questions =\"\"\"What is the Significance of Privilege Escalation Techniques\n",
    "Explain the Impact of Defense Evasion Techniques\n",
    "How do Adversaries Use Persistence Techniques\n",
    "What is the Role of Discovery Techniques\n",
    "Discuss the Use of Exfiltration Techniques\n",
    "What is a Man-in-the-Middle (MitM) attack and how can it be prevented?\n",
    "How does Cross-Site Scripting (XSS) work and what are the best practices to prevent it?\n",
    "What is Social Engineering and what strategies can be employed to mitigate its risks?\n",
    "How do Zero-Day vulnerabilities differ from other vulnerabilities and how can organizations protect against them?\n",
    "What is a Brute Force attack and what measures can be taken to secure systems against it?\n",
    "How does DNS Spoofing work and what are the defense mechanisms against it?\"\"\"\n",
    "\n",
    "questions = questions.split(\"\\n\")\n",
    "print(len(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j,i in enumerate(questions):\n",
    "    format = ''\n",
    "    rag_ans = rag_chain.invoke(i)\n",
    "    lora_ans = lora_llama.invoke(i)\n",
    "    format+= f\"## {str(j+26)+\". \"+i}\\n\\n### Rag:\\n{rag_ans}\\n\\n### Lora:\\n{lora_ans}\\n\\n\"\n",
    "    print(format)\n",
    "    with open(\"result.md\",'a') as f:\n",
    "        f.write(format)\n",
    "        f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
